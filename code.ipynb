{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\furta\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\furta\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "#ashlin\n",
    "!pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1:\n",
      "\n",
      "h2:\n",
      "Who We've Worked With\n",
      "\n",
      "p:\n",
      "GET IN TOUCH\n",
      "CONTACT US\n",
      "SUBSCRIBE\n",
      "\n",
      "Δ\n",
      "A boutique London-based PR agency supporting industry leaders worldwide. Aim Agency works to raise profile, refine messaging, and expand reach.\n",
      "For each brief, we take a strategic approach to determine the most effective communication channels and PR messages to reach your target audiences.\n",
      "Our clients include CEOs, senior executives, founders, entrepreneurs, tech investors, artists, philanthropists, high-net-worth individuals, and family offices.\n",
      "\n",
      "Δ\n",
      "PRIVACY POLICY  |  TERMS OF USE\n",
      "Copyright © 2024 Aim Agency\n",
      "\n",
      "li:\n",
      "ABOUT About Us Blogs Testimonials FAQ Careers Case Studies\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "SERVICES\n",
      "CONTACT\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "ABOUT About Us Blogs Testimonials FAQ Careers Case Studies\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "SERVICES\n",
      "CONTACT\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "ABOUT About Us Blogs Testimonials FAQ Careers Case Studies\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "SERVICES\n",
      "CONTACT\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "ABOUT About Us Blogs Testimonials FAQ Careers Case Studies\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "SERVICES\n",
      "CONTACT\n",
      "About Us\n",
      "Blogs\n",
      "Testimonials\n",
      "FAQ\n",
      "Careers\n",
      "Case Studies\n",
      "CHURCHILL HOUSE 137-139 BRENT STREET, LONDON, NW4 4DJ, UNITED KINGDOM.\n",
      "hello@aim-agency.com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Replace 'url' with the URL of the webpage you want to scrape\n",
    "url = 'https://aim-agency.com/'\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Initialize an empty dictionary to store the extracted text\n",
    "    extracted_text = {\n",
    "        'h1': [],\n",
    "        'h2': [],\n",
    "        'p': [],\n",
    "        'li': []\n",
    "    }\n",
    "    \n",
    "    # Find all <h1> tags and store their text in the dictionary\n",
    "    h1_tags = soup.find_all('h1')\n",
    "    for h1_tag in h1_tags:\n",
    "        extracted_text['h1'].append(h1_tag.text.strip())\n",
    "    \n",
    "    # Find all <h2> tags and store their text in the dictionary\n",
    "    h2_tags = soup.find_all('h2')\n",
    "    for h2_tag in h2_tags:\n",
    "        extracted_text['h2'].append(h2_tag.text.strip())\n",
    "    \n",
    "    # Find all <p> tags and store their text in the dictionary\n",
    "    p_tags = soup.find_all('p')\n",
    "    for p_tag in p_tags:\n",
    "        extracted_text['p'].append(p_tag.text.strip())\n",
    "    \n",
    "    # Find all <ul> and <ol> tags\n",
    "    list_tags = soup.find_all(['ul', 'ol'])\n",
    "    for list_tag in list_tags:\n",
    "        # Find all <li> tags within the list and store their text in the dictionary\n",
    "        list_items = list_tag.find_all('li')\n",
    "        for list_item in list_items:\n",
    "            extracted_text['li'].append(list_item.text.strip())\n",
    "    \n",
    "    # Print the extracted text stored in the dictionary\n",
    "    for tag, text_list in extracted_text.items():\n",
    "        print(f\"{tag}:\")\n",
    "        for text in text_list:\n",
    "            print(text)\n",
    "        print()\n",
    "else:\n",
    "    print(response)\n",
    "    print(\"Failed to retrieve the webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "mediapipe 0.9.0.1 requires protobuf<4,>=3.11, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.29.0 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-api-core<2.0.0dev,>=1.21.0, but you have google-api-core 2.18.0 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.29.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "GOOGLE_API_KEY= os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aim Agency is a London-based public relations agency that specializes in raising profiles, refining messaging, and expanding reach for industry leaders worldwide. They take a strategic approach to determine the most effective communication channels and PR messages to reach target audiences. Their clients include CEOs, senior executives, founders, entrepreneurs, tech investors, artists, philanthropists, and family offices. The agency is committed to providing personalized and tailored services to meet the specific needs of each client.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "# Configure your API key\n",
    "GOOGLE_API_KEY= os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=\"AIzaSyAZ0Jw5j08RZHDqYciL_G34-F6fl9Q-3w4\")\n",
    "\n",
    "# Initialize the Generative Model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "prompt=\"\"\"I am giving you the data scrapped from a website that describes it's services ,the data is structured in the following way ({h1:\" \" ,h2:\" \",p:\" \" ,li:\" \"}) i want you to go through it can understand what exactly the product does and give a description about it which should be 4 lines. The data is as follows \",\"\"\"  \n",
    "\n",
    "request=prompt+str(extracted_text)\n",
    "# Generate content\n",
    "response = model.generate_content(request)\n",
    "\n",
    "# Print the generated content\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
